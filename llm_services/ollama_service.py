# llm_services/ollama_service.py
import json
from openai import OpenAI
from typing import Dict, Any

from llm_services.abstract_service import AbstractLLMService
from config.settings import llm_settings, project_settings 

class OllamaService(AbstractLLMService):
    """
    ä½¿ç”¨ Ollama è¿è¡Œæœ¬åœ°å¤§æ¨¡å‹ã€‚
    Ollama æä¾›äº†å…¼å®¹ OpenAI çš„ API æ¥å£ã€‚
    """
    
    def __init__(self):
        # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ŒæŒ‡å‘æœ¬åœ° Ollama æœåŠ¡
        self.client = OpenAI(
            base_url=project_settings.OLLAMA_BASE_URL,
            api_key="ollama" # Ollama ä¸éœ€è¦çœŸå®çš„ API Keyï¼Œä½†åº“è¦æ±‚éç©º
        )
        self.model_name = llm_settings.MODEL_NAME
        self.temperature = llm_settings.TEMPERATURE
        self.timeout = llm_settings.TIMEOUT * 2 # æœ¬åœ°æ¨ç†å¯èƒ½è¾ƒæ…¢ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´

    def generate_response(self, system_prompt: str, user_prompt: str, **kwargs) -> Dict[str, Any]:
        
        try:
            print(f"ğŸ¦™ [Ollama] æ­£åœ¨è°ƒç”¨æœ¬åœ°æ¨¡å‹: {self.model_name}...")
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=self.temperature,
                timeout=self.timeout,
                response_format={"type": "json_object"} 
            )
            
            llm_output_str = response.choices[0].message.content.strip()
            
            # ç®€å•çš„ Markdown æ¸…ç† (æœ‰äº›æœ¬åœ°æ¨¡å‹å–œæ¬¢åŠ  ```json)
            if llm_output_str.startswith("```json"):
                llm_output_str = llm_output_str[7:]
            elif llm_output_str.startswith("```"):
                llm_output_str = llm_output_str[3:]
            
            if llm_output_str.endswith("```"):
                llm_output_str = llm_output_str[:-3]
                
            return json.loads(llm_output_str.strip())

        except Exception as e:
            raise RuntimeError(f"Ollama æœ¬åœ°è°ƒç”¨å¤±è´¥: {e}. è¯·ç¡®ä¿ Ollama å·²å¯åŠ¨ä¸”æ¨¡å‹ '{self.model_name}' å·²ä¸‹è½½ (ollama pull {self.model_name})")
