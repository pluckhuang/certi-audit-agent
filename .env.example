# .env.example
# 将此文件重命名为 .env，并填入您的 API Key

# --- LLM 配置 ---
# 可更换的模型名称: 
#   OpenAI: gpt-4o, gpt-4-turbo, etc.
#   Gemini: gemini-1.5-flash, gemini-1.5-pro
#   Local (Ollama): llama3, qwen2.5-coder, mistral, deepseek-coder
LLM_MODEL_NAME=gemini-2.5-flash 
LLM_TEMPERATURE=0.1

# --- API Keys (只需提供您使用的那个) ---
OPENAI_API_KEY=your_openai_key_here
GEMINI_API_KEY=your_gemini_key_here

# --- Local LLM (Ollama) ---
# 如果使用本地模型，请确保 Ollama 已启动 (ollama serve)
# 默认地址: http://localhost:11434/v1
OLLAMA_BASE_URL=http://localhost:11434/v1